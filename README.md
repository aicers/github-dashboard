# GitHub Dashboard

GitHub Dashboard collects GitHub organization data into PostgreSQL and exposes
configuration, sync controls, and analytics through a Next.js dashboard.

## AI-Driven Development Principles

- Most application code is intentionally produced by AI agents.
- We prioritize tools and frameworks that AI agents can handle with confidence.
- Comprehensive automated tests are treated as essential so that AI-authored
  code remains trustworthy, and those tests are generated by AI agents as well.
- AI agents contribute to both engineering and design efforts across the project.

## Prerequisites

- Node.js 22+
- npm 10+
- PostgreSQL 14+ running locally or reachable via connection string
- A GitHub OAuth App configured for your environments (see [docs/github-oauth-app.md](docs/github-oauth-app.md))
- (Optional) A GitHub personal access token with `read:user` and repository
  metadata scopes (`GITHUB_TOKEN`) for legacy data collection utilities

## Local Development

1. Install dependencies:

   ```bash
   npm install
   ```

1. Install Playwright browsers (one-time per machine):

   ```bash
   npx playwright install --with-deps
   ```

1. Provide environment variables (`npm run dev` reads from `.env.local` or the
   current shell). Copy `.env.example` to `.env.local` and replace the
   placeholders:

   ```bash
   export GITHUB_TOKEN=<ghp_token>
   export GITHUB_ORG=<github_org>
   export GITHUB_OAUTH_CLIENT_ID=<oauth_client_id>
   export GITHUB_OAUTH_CLIENT_SECRET=<oauth_client_secret>
   export GITHUB_ALLOWED_ORG=<allowed_org_slug>
   export DASHBOARD_ADMIN_IDS=owner_login,ops-team
   export APP_BASE_URL=http://localhost:3000   # production: https://your-domain
   export SESSION_SECRET=$(openssl rand -hex 32)
   export DATABASE_URL=postgres://<user>:<password>@localhost:5432/<database>
   export SYNC_INTERVAL_MINUTES=60
   export TODO_PROJECT_NAME="to-do list"   # optional; see below for details
   ```

1. Start the dev server:

   ```bash
   npm run dev
   ```

1. Visit the app (all dashboard routes require GitHub sign-in and organization
   membership):

   - `http://localhost:3000` — landing page with quick links
   - `http://localhost:3000/dashboard` — data collection controls & analytics
   - `http://localhost:3000/github-test` — GraphQL connectivity test page

GitHub authentication is mandatory. Authorized members are issued a signed
session cookie; non-members are redirected to `/auth/denied` with instructions
on granting access under **Settings → Applications → Authorized OAuth Apps**.
Full OAuth setup instructions live in [docs/github-oauth-app.md](docs/github-oauth-app.md).

Administrators are identified through `DASHBOARD_ADMIN_IDS`, a comma-separated
list of GitHub logins or node IDs. Admin users can modify organization-wide
settings (org name, sync cadence, excluded repositories/members), while all
authenticated users can adjust their personal timezone and week-start
preferences.

### PostgreSQL schema bootstrap

The first API call or dashboard render triggers schema creation (tables for
users, repositories, issues, pull requests, reviews, comments, and sync
metadata). Ensure `DATABASE_URL` points to a database the app can manage.

To reset the data store manually:

```bash
curl -X POST http://localhost:3000/api/sync/reset -d '{"preserveLogs":true}' \
  -H "Content-Type: application/json"
```

### Index maintenance script

Use the interactive helper to apply and validate dashboard-specific indexes on
an existing dataset (ensure `CREATE EXTENSION IF NOT EXISTS pg_trgm;` has been
run on the target database so trigram GIN indexes can build successfully):

```bash
node scripts/db/apply-indexes.mjs
```

Flags:

- `--concurrently` — build each index with `CREATE INDEX CONCURRENTLY` to avoid
  long-lived locks (slower but safe for live traffic)
- `--yes` — auto-confirm prompts while still respecting default answers
  (optional indexes and verification queries remain skipped unless explicitly
  enabled)
- `--include-optional` — include optional indexes (JSONB-wide GIN indexes used
  for experimentation) alongside the default set

Each step prints the DDL statement, runs `ANALYZE` on the affected table, and
offers to execute representative `EXPLAIN (ANALYZE, BUFFERS)` queries. After
verifying the impact, capture the same statements in a migration or schema
update so fresh environments do not need the interactive script.

### Data collection flows

- **Manual backfill** — choose a start date on the dashboard or call
  `POST /api/sync/backfill { startDate }` to fetch data up to the present.
- **Incremental sync** — toggle auto-sync on the dashboard or call
  `POST /api/sync/auto { enabled: true }`; it runs immediately and then every
  `SYNC_INTERVAL_MINUTES` minutes using the latest successful sync timestamp.
- **Status & analytics** — the dashboard consumes `GET /api/sync/status` and
  `GET /api/data/stats` to present sync logs, data freshness, counts, and top
  contributors/repositories.
<!-- markdownlint-disable MD013 -->
- **Stuck sync cleanup** — administrators can use the Sync tab’s “멈춘 동기화 정리”
  button (or call `POST /api/sync/admin/cleanup`) to mark lingering
  `running` sync runs/logs as failed so the real-time panel clears. As a manual
  fallback, run
  `UPDATE sync_runs SET status = 'failed', completed_at = NOW(), updated_at = NOW() WHERE status = 'running';`
  (and similar for `sync_log`) via `psql` or a SQL client.
<!-- markdownlint-enable MD013 -->

#### What each sync run does

Manual backfill and automatic sync share the same pipeline.

1. **GitHub data collection**
   `runCollection` fetches repositories, issues, discussions, pull requests,
   reviews, and comments through the GraphQL API and upserts them into
   PostgreSQL.
   - Every resource writes a `running → success/failed` entry to `sync_log`.
   - The latest `updated_at` timestamp is stored in `sync_state` so the next run
     can reuse it as the `since` boundary.

2. **Sync metadata updates**
   Before the run starts it creates a `sync_run` record; on completion it
   refreshes the `sync_config` `last_sync_*` fields and broadcasts Server-Sent
   Events (`run-started`, `run-completed`, `run-failed`, etc.) to the dashboard.

3. **Post-processing steps**
   After collection finishes three follow-up tasks run sequentially, each
   persisting its outcome to `sync_log`.
   - Apply issue status automation
   - Refresh the activity snapshot
   - Refresh activity caches

Automatic sync additionally schedules the next run, while manual backfill
repeats the same steps for each day slice in the requested range.

### Real-time sync stream

- **Server-Sent Events** — `GET /api/sync/stream` keeps an HTTP connection open
  (`Content-Type: text/event-stream`) and pushes run lifecycle updates
  (`run-started`, `log-started`, `log-updated`, `run-completed`, `run-failed`)
  plus periodic heartbeats. The dashboard subscribes with
  `new EventSource("/api/sync/stream")` to surface “backfill started → resources
  progressing → completed” across all tabs via a shared status panel.
- Events include run metadata (type, strategy, since/until window), per-resource
  log status, completion summaries, and failure messages. The panel falls back
  to `/api/sync/status` for initial hydration and whenever the SSE connection
  re-opens.
- No extra libraries are required—the server uses the built-in Next.js App
  Router streaming response API, and the browser relies on native `EventSource`
  with automatic reconnection. Expect a single SSE connection per browser tab
  (~50 concurrent clients are well within the Node runtime budget).

### Optional GitHub to-do project integration

If you want issue status, priority, start date, or other metadata to mirror a
specific GitHub Projects (beta) board, set `TODO_PROJECT_NAME` to the project’s
name (case-insensitive match). When provided, the sync pipeline will:

- import project status history so dashboard filters (for example `Todo`,
  `In Progress`) reflect the project board
- lock issue statuses that are managed by the project and surface project field
  values (priority, start date, etc.) in the UI

Leaving `TODO_PROJECT_NAME` unset (or blank) is also valid. In that case the
dashboard relies solely on statuses stored in the local database—manual updates
made from the dashboard continue to work, while project-driven fields and locks
are simply disabled. This is useful if you track issue progress entirely inside
the dashboard or maintain multiple GitHub projects and only want dashboard-side
state.

## Quality Tooling

- `npm run lint` — Biome linting (Rust binary via CI and local npm package)
- `npm run format` — Biome formatter (writes changes)
- `biome ci --error-on-warnings .` — direct CLI run that combines Biome's
  formatter and linter checks without writing files; it subsumes `npm run lint`
  (lint-only wrapper) while differing from `npm run format`, which applies
  formatting edits instead of reporting them
- `npm run typecheck` — `tsc --noEmit`
- `npm run test` — Vitest unit and component tests
- `npm run test:db` — PostgreSQL integration suite scoped by `vitest.db.config.ts`
  to `*.db.test.ts` specs; each spec imports `tests/helpers/postgres-container`
  to launch a disposable PostgreSQL 16 Testcontainer, injects its connection URI
  into `DATABASE_URL`, runs `ensureSchema()` so tables exist, and stops the
  container once the suite finishes. Ensure Docker (or Colima on macOS) is
  running first, and keep each spec responsible for cleaning its tables (for
  example with `TRUNCATE`) to stay isolated.
- `npm run test:watch` — watch mode
- `npm run test:e2e` — Playwright browser tests (requires the Playwright browser
  install step above); uses dedicated test harness routes under
  `/test-harness/*` such as:
  - SettingsView — `http://localhost:3000/test-harness/settings`
  - SyncControls — `http://localhost:3000/test-harness/sync`
  - Session bootstrap — `http://localhost:3000/test-harness/auth/session`
  - Analytics filters — `http://localhost:3000/test-harness/analytics`
  - People insights — `http://localhost:3000/test-harness/people`
  - Dashboard tabs — `http://localhost:3000/test-harness/dashboard-tabs`
- `npm run ci` — sequentially runs `biome ci --error-on-warnings .`,
  `npm run typecheck`, `npm run test`, and `npm run test:db`

## Continuous Integration

The GitHub Actions workflow (`.github/workflows/ci.yml`) starts a Postgres 16
service, generates an ephemeral `SESSION_SECRET`, and expects the following
repository secrets to be configured:

- `OAUTH_CLIENT_ID`
- `OAUTH_CLIENT_SECRET`
- `OAUTH_ALLOWED_ORG`

These values are used during end-to-end tests to exercise the GitHub OAuth
flow. Update them per environment as needed.

## Docker

Builds use the standalone Next.js output for small production images.

```bash
cp .env.example .env          # if you need a starting point
vim .env                      # set GitHub OAuth creds, DATABASE_URL, etc.
./infra/nginx/certs/generate.sh
docker compose up --build
```

Docker Compose reads environment values from `.env` in the project root. This
file is distinct from `.env.local`, which is used only by the local Next.js dev
server.

### Build & export a production image

When deploying to a linux/amd64 host (for example, from an Apple Silicon
workstation), build the image with `docker buildx`, verify it behind the HTTPS
proxy, and ship it as a tarball.

1. Build for the target platform and tag the image:

   ```bash
   docker buildx build --platform linux/amd64 -t github-dashboard:0.1.0 --load .
   ```

   > Replace `github-dashboard:0.1.0` with the tag you plan to deploy. The
   > command automatically uses your default builder (create one with
   > `docker buildx create --use` if missing). `--load` pulls the built image
   > into the local Docker daemon so the tar export in the next step works.

2. Optionally smoke-test locally over HTTPS:

   ```bash
   ./infra/nginx/certs/generate.sh   # creates local.crt/local.key for localhost
   docker compose up --build
   ```

   Visit `https://localhost` (accept the self-signed certificate if prompted),
   then stop the stack with `docker compose down`. Provide `GITHUB_TOKEN` and
   other secrets via `.env` before running.

3. Export the image to a tarball and transfer it to the server (copy your
   production TLS certificate and key alongside the tarball, or re-run the
   generation script there with the appropriate host names):

   ```bash
   docker save github-dashboard:0.1.0 -o github-dashboard-0.1.0.tar
   scp github-dashboard-0.1.0.tar user@server:/path/to/github-dashboard/
   ```

   > The bundled script issues certificates for `localhost`; replace
   > `infra/nginx/certs/local.crt` and `local.key` with files signed for your
   > real domain before serving traffic publicly.

4. On the server, load the tarball, install the HTTPS certificate, and restart
   the containers (adjust the commands to your setup):

   ```bash
   docker compose down
   docker load -i /path/to/github-dashboard/github-dashboard-0.1.0.tar
   docker compose up -d --force-recreate
   ```

   Ensure `/path/to/github-dashboard/infra/nginx/certs/local.crt` and
   `/path/to/github-dashboard/infra/nginx/certs/local.key` contain the
   certificate and key signed for your server before restarting the stack. The
   `--force-recreate` flag tears down and rebuilds all containers even when the
   configuration or images have not changed, guaranteeing that the freshly
   loaded image is used.

   > If you manage the container manually, use `docker stop <container>` followed
   > by `docker run ... github-dashboard:0.1.0` instead of the Compose commands.

The nginx proxy listens only on HTTPS (`https://localhost`) and redirects any
HTTP attempts to the secure endpoint.

- Node app: internal on port 3000 (reachable via the proxy only)
- nginx proxy: exposes port 443 (HTTPS) and forwards traffic to the app
  container. Certificates live in `infra/nginx/certs/`.

### Deployment modes

#### Using Docker Compose

Docker Compose keeps the application and nginx proxy definitions in
`docker-compose.yml`, letting you run the full stack with a single command:

```yaml
services:
  app:
    build: .
    env_file:
      - .env
    environment:
      NODE_ENV: production
      PORT: 3000
      HOSTNAME: 0.0.0.0
      GITHUB_TOKEN: ${GITHUB_TOKEN:-}
      GITHUB_ORG: ${GITHUB_ORG:-}
      DATABASE_URL: ${DATABASE_URL}
    restart: unless-stopped

  proxy:
    image: nginx:1.28.0
    depends_on:
      - app
    ports:
      - "443:443"
    volumes:
      - ./infra/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro
      - ./infra/nginx/certs:/etc/nginx/certs:ro
    restart: unless-stopped
```

1. Copy `.env`, TLS assets (`infra/nginx/certs/*`), and either the source tree
   or a pre-built image tarball to the server.
2. Run `docker compose up -d --build` the first time (or `--force-recreate`
   after loading a new tarball) to start both services. Compose injects the
   environment values from `.env` and mounts the nginx configuration automatically.

#### Using docker run for each container

If you prefer to manage containers manually, mirror the compose setup by
starting the app and proxy containers yourself:

1. Load the image and create a shared network:

   ```bash
   docker load -i github-dashboard-0.1.0.tar
   docker network create github-dashboard-net || true
   ```

2. Launch the application container with the required environment variables:

   ```bash
   docker stop github-dashboard-app 2>/dev/null || true
   docker rm github-dashboard-app 2>/dev/null || true
   docker run -d \
     --name github-dashboard-app \
     --env-file .env \
     --network github-dashboard-net \
     github-dashboard:0.1.0
   ```

3. Start the nginx proxy container and expose HTTPS:

   ```bash
   docker stop github-dashboard-proxy 2>/dev/null || true
   docker rm github-dashboard-proxy 2>/dev/null || true
   docker run -d \
     --name github-dashboard-proxy \
     --network github-dashboard-net \
     -p 443:443 \
     -v $(pwd)/infra/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro \
     -v $(pwd)/infra/nginx/certs:/etc/nginx/certs:ro \
     nginx:1.28.0
   ```

Maintain the same `.env` file (or equivalent secrets store) for both containers
and restart them with `docker restart <name>` when shipping updates.

## Project Structure

```text
src/app/             → Next.js App Router routes, layouts, and API handlers
src/components/      → Shared UI components (shadcn/ui + custom)
src/lib/             → Utilities (db, auth, GitHub client, sync scheduler)
src/lib/auth/        → GitHub OAuth, session, and membership helpers
docs/                → Setup guides (e.g., GitHub OAuth registration)
tests/               → Vitest specs, Playwright E2E suites, and helpers
public/              → Static assets served by Next.js
infra/               → Docker/nginx assets for HTTPS proxying
```

### Utility scripts

- `scripts/backfill-social-signals.ts` — one-off helper to rebuild the activity
  snapshot and social-signal caches. Run it when you want a full refresh outside
  the usual sync pipeline; add `--signals-only` to rebuild only the social-signal
  tables.
- `scripts/db/backup.mjs` — wraps `pg_dump` so you can produce database backups
  with a single command. Supports `--dir`, `--label`, `--format`, and
  `--pg-dump` flags for customizing the output location and filename.
- `scripts/run-db-tests.mjs` — verifies that PostgreSQL (or Testcontainers) is
  available, then runs `vitest` with `vitest.db.config.ts`. If no database is
  reachable it exits early, letting CI/local workflows skip DB-backed tests.

## Environment

Environment variables are parsed through `src/lib/env.ts`:
<!-- markdownlint-disable MD013 -->
| Variable | Required | Description |
| --- | --- | --- |
| `GITHUB_TOKEN` | ✅ | GitHub token with `read:user` + repository metadata scope |
| `GITHUB_ORG` | ✅ | Organization login to target for data collection |
| `GITHUB_OAUTH_CLIENT_ID` | ✅ | GitHub OAuth App client identifier |
| `GITHUB_OAUTH_CLIENT_SECRET` | ✅ | GitHub OAuth App client secret |
| `GITHUB_ALLOWED_ORG` | ✅ | GitHub organization slug allowed to sign in; non-admin users stay blocked until allowed teams or members are configured in Settings |
| `DASHBOARD_ADMIN_IDS` | ⛔ | Comma-separated GitHub logins or node IDs with admin privileges |
| `APP_BASE_URL` | ✅ | Absolute origin used to build OAuth callback URLs |
| `SESSION_SECRET` | ✅ | Secret key for signing session cookies |
| `DATABASE_URL` | ✅ | PostgreSQL connection string |
| `SYNC_INTERVAL_MINUTES` | ⛔ (default 60) | Interval for automatic incremental sync |
| `TODO_PROJECT_NAME` | ⛔ | Optional GitHub Projects board name to mirror issue metadata |
<!-- markdownlint-enable MD013 -->

Define them in `.env.local` for local development or provide them via your
hosting platform. Docker Compose reads from `.env` in the project root.
